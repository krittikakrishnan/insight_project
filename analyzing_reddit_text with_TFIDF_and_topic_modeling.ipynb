{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Subsetting-posts-by-contraceptive-first.\" data-toc-modified-id=\"Subsetting-posts-by-contraceptive-first.-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Subsetting posts by contraceptive first.</a></span></li><li><span><a href=\"#Let's-compare-topic-modeling-with-an-LDA-vs-an-NMF-with-the-posts-from-each-contraceptive-type.\" data-toc-modified-id=\"Let's-compare-topic-modeling-with-an-LDA-vs-an-NMF-with-the-posts-from-each-contraceptive-type.-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Let's compare topic modeling with an LDA vs an NMF with the posts from each contraceptive type.</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/krittikakrishnan/Desktop/Insight Project\"\n",
    "os.chdir(path)\n",
    "df = pd.read_csv(\"All Uncleaned Reddit Posts.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing the original title and selftext\n",
    "def standardize_text(new, text_field):\n",
    "    new[text_field] = new[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    new[text_field] = new[text_field].str.replace(r\"http\", \"\")\n",
    "    new[text_field] = new[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    new[text_field] = new[text_field].str.replace(r\"\\n\", \"\")\n",
    "    new[text_field] = new[text_field].str.replace(r\"[^A-Za-z0-9(),.!?@\\'\\`\\\"\\_\\n]\", \"\")\n",
    "    new[text_field] = new[text_field].str.replace(r\"@\", \"at\")\n",
    "#     new[text_field] = new[text_field].str.lower()\n",
    "    return new\n",
    "\n",
    "# new = standardize_text(uncleaned, \"title\")\n",
    "posts = standardize_text(df, \"selftext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = posts.drop([\"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            print(documents[doc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Running the TF-IDF Count Vectorizer in prep for Latent Dirichlet Allocation (LDA) for topic modeling\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(sentences[\"SENTENCE\"])\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 5\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
    "lda_W = lda_model.transform(tf)\n",
    "lda_H = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_top_words = 5\n",
    "no_top_documents = 2\n",
    "display_topics(lda_H, lda_W, tf_feature_names, sentences[\"SENTENCE\"], no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "no_top_words = 15\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is really cool! I would love to display the topics associated with the side effect & the contraceptive. Going to try doing that below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting posts by contraceptive first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Trying to automate dataframe extraction with a function and for loop. NOT CURRENTLY WORKING.\n",
    "#FIX LATER.\n",
    "##There has to be a quick way to do this. Spend time on this later. \n",
    "types = [\"iud\", \"pill\", \"patch\", \"ring\", \"tubal ligation\", \"condom\", \"implant\", \"depo\"]\n",
    "def counting_types(dataFrame, text_field, types):\n",
    "    d = {}\n",
    "    for i in range(dataFrame.shape[0]):\n",
    "        entry = dataFrame[text_field][i]\n",
    "        for j in range(len(types)):\n",
    "#             print(entry)\n",
    "            this_type = types[j]\n",
    "            if this_type in entry:\n",
    "#                 print(this_effect)\n",
    "                d[this_type] = pd.DataFrame(dataFrame[text_field].str.contains(this_type))\n",
    "#                 number[i,j] = 1\n",
    "    return d\n",
    "\n",
    "type_count = counting_types(reddit, \"selftext\", types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IUD = reddit[reddit['selftext'].str.contains(\"iud\", na = False)]\n",
    "IUD = pd.DataFrame(IUD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [(\"pill\", False), (\"iud\", True), (\"patch\", False), (\"condom\", False), (\"ring\", False), \n",
    "           (\"tubal ligation\", False), (\"depo\", False), (\"implant\", False)]\n",
    "new_IUD = reduce(lambda IUD, f: IUD[IUD[\"selftext\"].str.contains(f[0]) == f[1]], filters, IUD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index for subsetted dataframe\n",
    "IUD_1 = new_IUD.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pills = reddit[reddit['selftext'].str.contains(\"pill\", na = False)]\n",
    "pills = pd.DataFrame(pills)\n",
    "# pill.to_csv('pill_Data.csv')\n",
    "\n",
    "filters_pill = [(\"pill\", True), (\"iud\", False), (\"patch\", False), (\"condom\", False), (\"ring\", False), \n",
    "           (\"tubal ligation\", False), (\"depo\", False), (\"implant\", False)]\n",
    "new_pill = reduce(lambda pills, f: pills[pills[\"selftext\"].str.contains(f[0]) == f[1]], filters_pill, pills)\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "pills_1 = new_pill.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "condom = reddit[reddit['selftext'].str.contains(\"condoms\", na = False)]\n",
    "condom = pd.DataFrame(condom)\n",
    "# condom.to_csv('condom_Data.csv')\n",
    "\n",
    "filters_condom = [(\"pill\", False), (\"iud\", False), (\"patch\", False), (\"condoms\", True), (\"ring\", False), \n",
    "           (\"tubal ligation\", False), (\"depo\", False), (\"implant\", False)]\n",
    "new_condom = reduce(lambda condom, f: condom[condom[\"selftext\"].str.contains(f[0]) == f[1]], filters_condom, condom)\n",
    "\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "condom_1 = new_condom.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = reddit[reddit['selftext'].str.contains(\"patch\", na = False)]\n",
    "patch = pd.DataFrame(patch)\n",
    "# patch.to_csv('patch_Data.csv')\n",
    "\n",
    "filters_patch = [(\"pill\",False), (\"iud\", False), (\"patch\", True), (\"condom\", False), (\"ring\", False), \n",
    "           (\"tubal ligation\", False), (\"depo\", False), (\"implant\", False)]\n",
    "new_patch = reduce(lambda patch, f: patch[patch[\"selftext\"].str.contains(f[0]) == f[1]], filters_patch, patch)\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "patch_1 = new_patch.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "implant = reddit[reddit['selftext'].str.contains(\"implant\", na = False)]\n",
    "implant = pd.DataFrame(implant)\n",
    "# implant.to_csv('implant_Data.csv')\n",
    "\n",
    "filters_implant = [(\"pill\",False), (\"iud\", False), (\"patch\", False), (\"condom\", False), (\"ring\", False), \n",
    "           (\"tubal ligation\", False), (\"depo\", False), (\"implant\", True)]\n",
    "new_implant = reduce(lambda implant, f: implant[implant[\"selftext\"].str.contains(f[0]) == f[1]], filters_implant, implant)\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "implant_1 = new_implant.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ring = reddit[reddit['selftext'].str.contains(\"ring\", na = False)]\n",
    "ring = pd.DataFrame(ring)\n",
    "# ring.to_csv('ring_Data.csv')\n",
    "\n",
    "filters_ring = [(\"pill\",False), (\"iud\", False), (\"patch\", False), (\"condom\", False), (\"ring\", True), \n",
    "           (\"tubal ligation\", False), (\"depo\", False), (\"implant\", False)]\n",
    "new_ring = reduce(lambda ring, f: ring[ring[\"selftext\"].str.contains(f[0]) == f[1]], filters_ring, ring)\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "ring_1 = new_ring.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "depo = reddit[reddit['selftext'].str.contains(\"depo\", na = False)]\n",
    "depo = pd.DataFrame(depo)\n",
    "# ring.to_csv('ring_Data.csv')\n",
    "\n",
    "filters_depo = [(\"pill\",False), (\"iud\", False), (\"patch\", False), (\"condom\", False), (\"ring\", False), \n",
    "           (\"tubal ligation\", False), (\"depo\", True), (\"implant\", False)]\n",
    "new_depo = reduce(lambda depo, f: depo[depo[\"selftext\"].str.contains(f[0]) == f[1]], filters_depo, depo)\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "depo_1 = new_depo.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_tied = reddit[reddit['selftext'].str.contains(\"tube\", na = False)]\n",
    "tubes_tied = pd.DataFrame(tubes_tied)\n",
    "# tubes_tied.to_csv('tubes_tied_Data.csv')\n",
    "\n",
    "filters_tubes = [(\"pill\",False), (\"iud\", False), (\"patch\", False), (\"condom\", False), (\"ring\", False), \n",
    "           (\"tube\", True), (\"depo\", False), (\"implant\", False)]\n",
    "new_tubes = reduce(lambda tubes_tied, f: tubes_tied[tubes_tied[\"selftext\"].str.contains(f[0]) == f[1]], filters_tubes, tubes_tied)\n",
    "\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "tubes_tied_1 = new_tubes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's compare topic modeling with an LDA vs an NMF with the posts from each contraceptive type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 100\n",
    "no_topics = 10\n",
    "no_top_words = 5\n",
    "no_top_documents = 3\n",
    "\n",
    "###Running the TF-IDF Count Vectorizer in prep for Latent Dirichlet Allocation (LDA) for topic modeling\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "\n",
    "###Running the TF-IDF Vectorizer in prep for non-Negative Matrix Factorization (NMF) for topic modeling\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "    topic_title_list = []\n",
    "    topic_text_list = []\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "#          print(\"Topic %d:\" % (topic_idx))\n",
    "        topic_title_list.append(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            topic_text_list.append(documents[doc_index])\n",
    "            \n",
    "    return topic_title_list, topic_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_iud = tf_vectorizer.fit_transform(IUD_1[\"selftext\"])\n",
    "tf_iud_feature_names = tf_vectorizer.get_feature_names()\n",
    "lda_iud = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf_iud)\n",
    "lda_iud_W = lda_iud.transform(tf_iud)\n",
    "lda_iud_H = lda_iud.components_\n",
    "IUD_title_list, IUD_text_list = display_topics(lda_iud_H, lda_iud_W, tf_iud_feature_names, IUD_1[\"selftext\"], no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['just period days cramps got',\n",
       " 'just copper experiences right day',\n",
       " 'weight got cervix pretty thing',\n",
       " 'weight gain just week ve',\n",
       " 'said skyla hormones don morning',\n",
       " 'doctor pain told having feel',\n",
       " 'period spotting pain ve experience',\n",
       " 'copper control just did hormonal',\n",
       " 'im days experience having today',\n",
       " 've mirena going know doctor']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IUD_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_iud = tfidf_vectorizer.fit_transform(IUD_1[\"selftext\"])\n",
    "tfidf_iud_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "nmf_iud = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf_iud)\n",
    "nmf_iud_W = nmf_iud.transform(tfidf_iud)\n",
    "nmf_iud_H = nmf_iud.components_\n",
    "IUD_NMF_titles, IUD_NMF_text = display_topics(nmf_iud_H, nmf_iud_W, tfidf_iud_feature_names, IUD_1[\"selftext\"], no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['just feel like got really',\n",
       " 'period bleeding months days periods',\n",
       " 'weight gain week doctor ve',\n",
       " 'sex ve day time having',\n",
       " 'cramps pretty cramping got week',\n",
       " 'pain painful insertion cervix experience',\n",
       " 'copper did long painful body',\n",
       " 'im paragard pregnant does experiences',\n",
       " 'skyla haven taking years said',\n",
       " 'control birth appointment years just']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IUD_NMF_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_iud_W[0]\n",
    "lda_iud_sum = np.sum(lda_iud_W, axis = 0)\n",
    "np.argmax(lda_iud_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93570318, 0.00714383, 0.00714357, 0.00714397, 0.00714348,\n",
       "       0.00714366, 0.00714557, 0.00714454, 0.00714369, 0.0071445 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_iud_W[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_iud_sum = np.sum(lda_iud_W, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(lda_iud_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IUD_top_topics = IUD_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['just period days cramps got',\n",
       " 'just copper experiences right day',\n",
       " 'weight got cervix pretty thing',\n",
       " 'weight gain just week ve',\n",
       " 'said skyla hormones don morning',\n",
       " 'doctor pain told having feel',\n",
       " 'period spotting pain ve experience',\n",
       " 'copper control just did hormonal',\n",
       " 'im days experience having today',\n",
       " 've mirena going know doctor']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IUD_top_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [0,1,2]\n",
    "IUD_top_docs = [IUD_text_list[i] for i in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Hi everyone!! I got the Skyla IUD (like Mirena only a tiny bit smaller) about a month ago. Everything went relatively smoothly with insertion and such and I was feeling optimistic about how I would react to it. About a week ago (3 weeks after insertion) I started feeling numbness and tingling on and off in my right upper arm. I tried to ignore it as I figured I probably just sat too long in the same position or bothered a nerve or something.The next day the numbness was more intense in that arm and much more constant. I went to bed hoping it would subside but woke up at 3 AM with a totally numb arm and went to the ER in a panic. They did some blood, urine, and dexterity tests and everything came back normal so they told me not to fret and it would probably get better.The next day my right leg started going numb. I tried not to worry but it was making me very anxious and I ended up going to the ER again. They ran similar tests along with a CAT scan and everything looked normal again.The next day it had spread to my neck and face and I saw my family doctor who was proceeding to set up a brain MRI and appointment to see and neurologist to see if there was something like MS going on, which he stressed was unlikely. He also said it couldn't be a pinched nerve because that would only spread to one area, not all over the body.Through all of this I kept telling every doctor that the only thing that has changed in my life in the last month was getting an IUD, and I felt like it could have been the cause. They all told me it doesn't seem medically probable, but something was telling me that was the issue.I ended up doing some searching online to see if anyone had similar experiences to me, and I found multiple forums with women detailing their MS like symptoms weeks to months after getting hormonal IUDs, and having the numbness subside weeks after getting them removed. I finally felt like I wasn't insane for having this hunch and decided to get mine removed this morning.I'm hoping that my symptoms start to subside soon. I recognize that this is a very uncommon reaction and that tons of people have great experiences, and I cannot say this is 100  the cause of these symptoms, but it feels like my body has been telling me to get the IUD out. I am not trying to scare anyone out of IUDs at all but just putting my experience out there, maybe someone else has had a similar experience. Thanks for reading and feel free to ask anything. I will be updating in a few weeks to let you guys know if my symptoms have started to go away. Fingers crossed.Edit  typos  ) Edit 2  All of my numbness and malaise disappeared within two weeks of iud removal. Just an update. All scans test blood work I did came back normal, and my symptoms gradually diminished within two weeks post removal.\",\n",
       " 'I just got my iud (kyleena) inserted about 2 months ago. The actual procedure itself wasn t bad for me. I was expecting it to be extremely painful after reading some other posts. I probably bled the first 2 days after getting it then nothing until my period came 8 days later. My period started on time, but the cramps and bleeding were pretty bad and I bled for 2.5 weeks. Then no blood for maybe 9 days. Now I am bleeding again. This time I have no cramps and the bleeding is on the lighter side, but still more than what I would consider to be spotting. It s been over 3 weeks now. So basically, I am getting a little discouraged because I am ALWAYS bleeding. The guy I m seeing has expressed before we started having sex how he  doesn t ride the red river . Haha. However, he s made an exception and we ve had sex a few times now, but I know he s not as into it as he would be if there wasn t any blood involved (understandably so). So anyways, I don t mind having sex while bleeding but I do love when he goes down on me and fingers me, but we haven t been able to do those things in a while. I feel like the bleeding is preventing me from getting the satisfaction I want and as often as I want it. Does anyone else feel like their iud has impacted their sex life negatively, especially in the beginning? Also, how did you work around it and when did the bleeding stop for you? I was told the irregular bleeding could go on for 9 months and I am really hoping that is not the case.',\n",
       " \"Okay listen, I know that everyone is different, and I know that what works for you may not work for others. But I just wanted to talk about my (so far) positive experience with Skyla.  BACK STORY  I know that its only been 24hrs but when I was getting ready to make the choice to hop on birth control I was skeptical for about 4 years. Everyone in the internet community just seemed to have such negative experiences that I was beyond scared. I am 21 years old and have been sleeping with the same person for 4 yrs and decided to finally see a gyno and choose a type of birth control. I chose the IUD because less hormones and it was clear there was heavy bias towards it in the USA.  Just some info on me   I get cramps but they usually go away after the first day and the severity of the pain varies, sometimes its painful other times its doable but taking medication almost always stops my cramps. GETTING THE IUD So listen getting the iud is no cake walk, its an invasive painful feeling and I cried when it was inserted. I took 600 mg aleve and 420 Motrin right after the procedure.I experienced no cramping but I did just want to take it easy cause the pain I felt was just so draining. I slept the rest of the day and Ive been functioning just fine! I did take Motrin before bed because  I felt a slight jab and didn't wanna take any chances. But here I am on reddit writing down my experience !\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IUD_top_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IUD_titles = pd.DataFrame(IUD_top_topics).reset_index()\n",
    "IUD_text = pd.DataFrame(IUD_top_docs).reset_index()\n",
    "\n",
    "IUD_text.columns = ['index', 'IUD']\n",
    "IUD_titles.columns = ['index', 'IUD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_pills = tf_vectorizer.fit_transform(pills_1[\"selftext\"])\n",
    "tf_pills_feature_names = tf_vectorizer.get_feature_names()\n",
    "lda_pills = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf_pills)\n",
    "lda_pills_W = lda_pills.transform(tf_pills)\n",
    "lda_pills_H = lda_pills.components_\n",
    "pills_title_list, pills_text_list = display_topics(lda_pills_H, lda_pills_W, tf_pills_feature_names, pills_1[\"selftext\"], no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pills_sum = np.sum(lda_pills_W, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pills_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(lda_pills_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pills_top_topics = pills_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [27,28,29]\n",
    "pills_top_docs = [pills_text_list[i] for i in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pills_titles = pd.DataFrame(pills_top_topics).reset_index()\n",
    "pills_text = pd.DataFrame(pills_top_docs).reset_index()\n",
    "\n",
    "pills_text.columns = ['index', 'Pills']\n",
    "pills_titles.columns = ['index', 'Pills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ring = tf_vectorizer.fit_transform(ring_1[\"selftext\"])\n",
    "tf_ring_feature_names = tf_vectorizer.get_feature_names()\n",
    "lda_ring = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf_ring)\n",
    "lda_ring_W = lda_ring.transform(tf_ring)\n",
    "lda_ring_H = lda_ring.components_\n",
    "ring_title_list, ring_text_list = display_topics(lda_ring_H, lda_ring_W, tf_ring_feature_names, ring_1[\"selftext\"], no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_ring_sum = np.sum(lda_ring_W, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_ring_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(lda_ring_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_top_topics = ring_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [6,7,8]\n",
    "ring_top_docs = [ring_text_list[i] for i in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_titles = pd.DataFrame(ring_top_topics).reset_index()\n",
    "ring_text = pd.DataFrame(ring_top_docs).reset_index()\n",
    "\n",
    "ring_text.columns = ['index', 'Vaginal ring']\n",
    "ring_titles.columns = ['index', 'Vaginal ring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_depo = tf_vectorizer.fit_transform(depo_1[\"selftext\"])\n",
    "tf_depo_feature_names = tf_vectorizer.get_feature_names()\n",
    "lda_depo = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf_depo)\n",
    "lda_depo_W = lda_depo.transform(tf_depo)\n",
    "lda_depo_H = lda_depo.components_\n",
    "depo_title_list, depo_text_list = display_topics(lda_depo_H, lda_depo_W, tf_depo_feature_names, depo_1[\"selftext\"], no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_depo_sum = np.sum(lda_depo_W, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_depo_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(lda_depo_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depo_top_topics = depo_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [0,1,2]\n",
    "depo_top_docs = [depo_text_list[i] for i in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depo_titles = pd.DataFrame(depo_top_topics).reset_index()\n",
    "depo_text = pd.DataFrame(depo_top_docs).reset_index()\n",
    "\n",
    "depo_text.columns = ['index', 'Depo-Provera']\n",
    "depo_titles.columns = ['index', 'Depo-Provera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_implant = tf_vectorizer.fit_transform(implant_1[\"selftext\"])\n",
    "tf_implant_feature_names = tf_vectorizer.get_feature_names()\n",
    "lda_implant = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf_implant)\n",
    "lda_implant_W = lda_implant.transform(tf_implant)\n",
    "lda_implant_H = lda_implant.components_\n",
    "implant_title_list, implant_text_list = display_topics(lda_implant_H, lda_implant_W, tf_implant_feature_names, implant_1[\"selftext\"], no_top_words, no_top_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_implant_sum = np.sum(lda_implant_W, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_implant_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(lda_implant_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implant_top_topics = implant_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [15,16,17]\n",
    "implant_top_docs = [implant_text_list[i] for i in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implant_titles = pd.DataFrame(implant_top_topics).reset_index()\n",
    "implant_text = pd.DataFrame(implant_top_docs).reset_index()\n",
    "\n",
    "implant_text.columns = ['index', 'Implant']\n",
    "implant_titles.columns = ['index', 'Implant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_patch = tf_vectorizer.fit_transform(patch_1[\"selftext\"])\n",
    "tf_patch_feature_names = tf_vectorizer.get_feature_names()\n",
    "lda_patch = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf_patch)\n",
    "lda_patch_W = lda_patch.transform(tf_patch)\n",
    "lda_patch_H = lda_patch.components_\n",
    "patch_title_list, patch_text_list = display_topics(lda_patch_H, lda_patch_W, tf_patch_feature_names, patch_1[\"selftext\"], no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_patch_sum = np.sum(lda_patch_W, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_patch_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(lda_patch_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_top_topics = patch_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [0,1,2]\n",
    "patch_top_docs = [patch_text_list[i] for i in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_titles = pd.DataFrame(patch_top_topics).reset_index()\n",
    "patch_text = pd.DataFrame(patch_top_docs).reset_index()\n",
    "\n",
    "patch_text.columns = ['index', 'Patch']\n",
    "patch_titles.columns = ['index', 'Patch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_condom = tf_vectorizer.fit_transform(condom_1[\"selftext\"])\n",
    "tf_condom_feature_names = tf_vectorizer.get_feature_names()\n",
    "lda_condom = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf_condom)\n",
    "lda_condom_W = lda_condom.transform(tf_condom)\n",
    "lda_condom_H = lda_condom.components_\n",
    "condom_title_list, condom_text_list = display_topics(lda_condom_H, lda_condom_W, tf_condom_feature_names, condom_1[\"selftext\"], no_top_words, no_top_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_condom_sum = np.sum(lda_condom_W, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_condom_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(lda_condom_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condom_top_topics = condom_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [24,25,26]\n",
    "condom_top_docs = [condom_text_list[i] for i in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condom_titles = pd.DataFrame(condom_top_topics).reset_index()\n",
    "condom_text = pd.DataFrame(condom_top_docs).reset_index()\n",
    "\n",
    "condom_text.columns = ['index', 'Condom']\n",
    "condom_titles.columns = ['index', 'Condom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_tubes = tf_vectorizer.fit_transform(tubes_tied_1[\"selftext\"])\n",
    "tf_tubes_feature_names = tf_vectorizer.get_feature_names()\n",
    "lda_tubes = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf_tubes)\n",
    "lda_tubes_W = lda_tubes.transform(tf_tubes)\n",
    "lda_tubes_H = lda_tubes.components_\n",
    "tubes_title_list, tubes_text_list = display_topics(lda_tubes_H, lda_tubes_W, tf_tubes_feature_names, tubes_tied_1[\"selftext\"], no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tubes_sum = np.sum(lda_tubes_W, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tubes_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(lda_tubes_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_top_topics = tubes_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [6,7,8]\n",
    "tubes_top_docs = [tubes_text_list[i] for i in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_titles = pd.DataFrame(tubes_top_topics).reset_index()\n",
    "tubes_text = pd.DataFrame(tubes_top_docs).reset_index()\n",
    "\n",
    "tubes_text.columns = ['index', 'Tubal ligation']\n",
    "tubes_titles.columns = ['index', 'Tubal ligation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Join all the dataframes\n",
    "text_data_frames = [tubes_text, IUD_text, pills_text, patch_text,\n",
    "              implant_text, ring_text, condom_text, depo_text]\n",
    "\n",
    "text_merged = functools.reduce(lambda  left,right: pd.merge(left,right,on=['index'],\n",
    "                                            how='outer'), text_data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join all the dataframes\n",
    "titles_data_frames = [tubes_titles, IUD_titles, pills_titles, patch_titles,\n",
    "              implant_titles, ring_titles, condom_titles, depo_titles]\n",
    "\n",
    "titles_merged = functools.reduce(lambda  left,right: pd.merge(left,right,on=['index'],\n",
    "                                            how='outer'), titles_data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_merged.to_csv(\"All Contraceptive Text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_merged.to_csv(\"All Contraceptive Topics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
