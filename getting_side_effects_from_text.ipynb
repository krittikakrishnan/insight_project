{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import string, math, time, collections, pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk.corpus\n",
    "import nltk.tokenize\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import gensim\n",
    "import os\n",
    "import nltk, re, pprint\n",
    "import textblob\n",
    "import stanfordcorenlp\n",
    "import seaborn as sns\n",
    "import functools\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This takes the json structure from the pushshift api\n",
    "with urllib.request.urlopen('https://api.pushshift.io/reddit/search/submission/?subreddit=BirthControl&metadata=true&after=30&size=500') as response:\n",
    "    file = response.read()\n",
    "\n",
    "#Here we're using the json package to convert the json content into a dictionary.\n",
    "#The API returns a dictionary with one element (key 'data') which is a list of dictionaries. We can access this list of dictionaries with parsed_json['data']    \n",
    "parsed = json.loads(file)\n",
    "\n",
    "#Using pandas, we are taking the list of dictionries and converting it into a DataFrame, and then exporting the DataFrame as a csv file.\n",
    "BC_dataframe_uncleaned = pd.DataFrame(parsed['data'])\n",
    "BC_dataframe_uncleaned.to_csv('database.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read in our two years worth of reddit posts\n",
    "path = \"/Users/krittikakrishnan/Desktop/Insight Project\"\n",
    "os.chdir(path)\n",
    "BC_dataframe_uncleaned = pd.read_csv(\"BC_sub_2yr.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with just the title and body\n",
    "\n",
    "uncleaned = BC_dataframe_uncleaned[['selftext', 'id']].copy()\n",
    "uncleaned = uncleaned.fillna(\"No text available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20912</th>\n",
       "      <td>Hi all, I have the Implanon implant and it's g...</td>\n",
       "      <td>4p17x1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20913</th>\n",
       "      <td>I'm making the appointment to get my implant r...</td>\n",
       "      <td>4p1rwg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20914</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>4p1yi6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20915</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>4p1yvx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20916</th>\n",
       "      <td>Well its all in the title, but I have recently...</td>\n",
       "      <td>4p203l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20917</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>4p2ded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20918</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>4p2ibe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20919</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>4p2n9j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20920</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>4p30cy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20921</th>\n",
       "      <td>I'm an 18 year old who's had Nexplanon in for ...</td>\n",
       "      <td>4p3g2g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                selftext      id\n",
       "20912  Hi all, I have the Implanon implant and it's g...  4p17x1\n",
       "20913  I'm making the appointment to get my implant r...  4p1rwg\n",
       "20914                                          [deleted]  4p1yi6\n",
       "20915                                          [deleted]  4p1yvx\n",
       "20916  Well its all in the title, but I have recently...  4p203l\n",
       "20917                                          [deleted]  4p2ded\n",
       "20918                                          [deleted]  4p2ibe\n",
       "20919                                          [deleted]  4p2n9j\n",
       "20920                                          [deleted]  4p30cy\n",
       "20921  I'm an 18 year old who's had Nexplanon in for ...  4p3g2g"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncleaned.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncleaned.to_csv(\"All Uncleaned Reddit Posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing the original title and selftext\n",
    "def standardize_text(new, text_field):\n",
    "    new[text_field] = new[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    new[text_field] = new[text_field].str.replace(r\"http\", \"\")\n",
    "    new[text_field] = new[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    new[text_field] = new[text_field].str.replace(r\"\\n\", \"\")\n",
    "    new[text_field] = new[text_field].str.replace(r\"[^A-Za-z0-9(),.!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "#     new[text_field] = new[text_field].str.replace(r\"@\", \"at\")\n",
    "    new[text_field] = new[text_field].str.lower()\n",
    "    return new\n",
    "\n",
    "# new = standardize_text(uncleaned, \"title\")\n",
    "new = standardize_text(uncleaned, \"selftext\")\n",
    "new = standardize_text(uncleaned, \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So at this point we have a dataframe with rows of IDs and text that has been split into sentences for each ID post.  \n",
    "**We will now need to find the particular sentences that have the side effects that we are interested in.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.to_csv(\"All Reddit Posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for row in new.itertuples():\n",
    "    for sentence in sent_tokenize(row[1]):\n",
    "        if sentence != '':\n",
    "            sentences.append((row[2], sentence))\n",
    "new_df = pd.DataFrame(sentences, columns=['ID', 'SENTENCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SENTENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124713</th>\n",
       "      <td>4p3g2g</td>\n",
       "      <td>i'm an 18 year old who's had nexplanon in for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124714</th>\n",
       "      <td>4p3g2g</td>\n",
       "      <td>i was told to try it out for a year and if i d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124715</th>\n",
       "      <td>4p3g2g</td>\n",
       "      <td>i switched to nexplanon after being on the pil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124716</th>\n",
       "      <td>4p3g2g</td>\n",
       "      <td>originally i was on it for cramping and irregu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124717</th>\n",
       "      <td>4p3g2g</td>\n",
       "      <td>with nexplanon i have very irregular periods t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124718</th>\n",
       "      <td>4p3g2g</td>\n",
       "      <td>its very light for a while, gets heavier at ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124719</th>\n",
       "      <td>4p3g2g</td>\n",
       "      <td>it's very inconsistent and frustrating since i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124720</th>\n",
       "      <td>4p3g2g</td>\n",
       "      <td>overall, my cramps have mostly stopped and i'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124721</th>\n",
       "      <td>4p3g2g</td>\n",
       "      <td>have any other women had these issues with nex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124722</th>\n",
       "      <td>4p3g2g</td>\n",
       "      <td>does it get better after a year or am i doomed?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                           SENTENCE\n",
       "124713  4p3g2g  i'm an 18 year old who's had nexplanon in for ...\n",
       "124714  4p3g2g  i was told to try it out for a year and if i d...\n",
       "124715  4p3g2g  i switched to nexplanon after being on the pil...\n",
       "124716  4p3g2g  originally i was on it for cramping and irregu...\n",
       "124717  4p3g2g  with nexplanon i have very irregular periods t...\n",
       "124718  4p3g2g  its very light for a while, gets heavier at ni...\n",
       "124719  4p3g2g  it's very inconsistent and frustrating since i...\n",
       "124720  4p3g2g  overall, my cramps have mostly stopped and i'm...\n",
       "124721  4p3g2g  have any other women had these issues with nex...\n",
       "124722  4p3g2g    does it get better after a year or am i doomed?"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\"iud\", \"pill\", \"patch\", \"ring\", \"tubal ligation\", \"condom\", \"implant\", \"depo\"]\n",
    "def counting_types(dataFrame, text_field, types):\n",
    "    number = np.zeros([dataFrame.shape[0],len(types)])\n",
    "    for i in range(dataFrame.shape[0]):\n",
    "        entry = dataFrame[text_field][i]\n",
    "        for j in range(len(types)):\n",
    "#             print(entry)\n",
    "            this_number = types[j]\n",
    "            if this_number in entry:\n",
    "#                 print(this_effect)\n",
    "                number[i,j] = 1\n",
    "    return number\n",
    "\n",
    "type_count = counting_types(new_df, \"SENTENCE\", types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_counts = pd.DataFrame(type_count, columns = types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "types_sum = type_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_sum = pd.DataFrame(types_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iud</th>\n",
       "      <td>8255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pill</th>\n",
       "      <td>14526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patch</th>\n",
       "      <td>705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring</th>\n",
       "      <td>8555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tubal ligation</th>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condom</th>\n",
       "      <td>2525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>implant</th>\n",
       "      <td>2184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depo</th>\n",
       "      <td>1005.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "iud              8255.0\n",
       "pill            14526.0\n",
       "patch             705.0\n",
       "ring             8555.0\n",
       "tubal ligation     52.0\n",
       "condom           2525.0\n",
       "implant          2184.0\n",
       "depo             1005.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_sum.columns=['sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_sum = type_sum.sort_values('sum', ascending = False)\n",
    "type_sum.to_csv(\"Frequency of BC Types in Reddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a39c3cdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "types_plot = sns.barplot(x = type_sum['sum'], y = type_sum.index, palette = \"Blues_d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SENTENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8s6n5g</td>\n",
       "      <td>i, myself, have a copper iud (either paragard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8s87fp</td>\n",
       "      <td>looking for advice from anyway who has had an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8s87fp</td>\n",
       "      <td>i'm booking in for an iud insertion this week ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8s8l0d</td>\n",
       "      <td>i'm going to be getting a kyleena iud in 3 weeks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8s9hu2</td>\n",
       "      <td>i got the mirena iud last year in september.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8s9hu2</td>\n",
       "      <td>a couple days ago i started bleeding and havin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8s9llg</td>\n",
       "      <td>my obgyn now no longer wants me having an iud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8sanno</td>\n",
       "      <td>i have an iud, so i m not worried about being ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8sb4qj</td>\n",
       "      <td>my doctor suggested i try an iud since the hor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8sb4qj</td>\n",
       "      <td>from anyone who has had a hormonal iud, could ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                           SENTENCE\n",
       "0  8s6n5g  i, myself, have a copper iud (either paragard ...\n",
       "1  8s87fp  looking for advice from anyway who has had an ...\n",
       "2  8s87fp  i'm booking in for an iud insertion this week ...\n",
       "3  8s8l0d  i'm going to be getting a kyleena iud in 3 weeks.\n",
       "4  8s9hu2       i got the mirena iud last year in september.\n",
       "5  8s9hu2  a couple days ago i started bleeding and havin...\n",
       "6  8s9llg  my obgyn now no longer wants me having an iud ...\n",
       "7  8sanno  i have an iud, so i m not worried about being ...\n",
       "8  8sb4qj  my doctor suggested i try an iud since the hor...\n",
       "9  8sb4qj  from anyone who has had a hormonal iud, could ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subsetting dataframe based on the user's input (for now, IUD)\n",
    "\n",
    "IUD = new_df[new_df['SENTENCE'].str.contains(\"iud\")]\n",
    "IUD = pd.DataFrame(IUD)\n",
    "# IUD.to_csv('IUD_Data.csv')\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "IUD = IUD.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pill = new_df[new_df['SENTENCE'].str.contains(\"pill\")]\n",
    "pill = pd.DataFrame(pill)\n",
    "# pill.to_csv('pill_Data.csv')\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "pill = pill.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "condom = new_df[new_df['SENTENCE'].str.contains(\"condom\")]\n",
    "condom = pd.DataFrame(condom)\n",
    "# condom.to_csv('condom_Data.csv')\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "condom = condom.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = new_df[new_df['SENTENCE'].str.contains(\"patch\")]\n",
    "patch = pd.DataFrame(patch)\n",
    "# patch.to_csv('patch_Data.csv')\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "patch = patch.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "implant = new_df[new_df['SENTENCE'].str.contains(\"implant\")]\n",
    "implant = pd.DataFrame(implant)\n",
    "# implant.to_csv('implant_Data.csv')\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "implant = implant.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ring = new_df[new_df['SENTENCE'].str.contains(\"ring\")]\n",
    "ring = pd.DataFrame(ring)\n",
    "# ring.to_csv('ring_Data.csv')\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "ring = ring.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "depo = new_df[new_df['SENTENCE'].str.contains(\"depo\")]\n",
    "depo = pd.DataFrame(depo)\n",
    "# ring.to_csv('ring_Data.csv')\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "depo = depo.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_tied = new_df[new_df['SENTENCE'].str.contains(\"tubes tied\")]\n",
    "tubes_tied = pd.DataFrame(tubes_tied)\n",
    "# tubes_tied.to_csv('tubes_tied_Data.csv')\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "tubes_tied = tubes_tied.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubal_ligation = new_df[new_df['SENTENCE'].str.contains(\"tubal ligation\")]\n",
    "tubal_ligation = pd.DataFrame(tubal_ligation)\n",
    "# tubes_tied.to_csv('tubes_tied_Data.csv')\n",
    "\n",
    "#reset index for subsetted dataframe\n",
    "tubal_ligation = tubal_ligation.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['ID', 'SENTENCE'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-42ce49b60c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtubes_tied\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtubal_ligation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   5314\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5315\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 5316\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   5317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5318\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   5329\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[1;32m   5330\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5331\u001b[0;31m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[1;32m   5332\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     56\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                          validate=validate)\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         llabels, rlabels = items_overlap_with_suffix(ldata.items, lsuf,\n\u001b[0;32m--> 588\u001b[0;31m                                                      rdata.items, rsuf)\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0mlindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mleft_indexer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mitems_overlap_with_suffix\u001b[0;34m(left, lsuffix, right, rsuffix)\u001b[0m\n\u001b[1;32m   5024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5025\u001b[0m             raise ValueError('columns overlap but no suffix specified: %s' %\n\u001b[0;32m-> 5026\u001b[0;31m                              to_rename)\n\u001b[0m\u001b[1;32m   5027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5028\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlrenamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['ID', 'SENTENCE'], dtype='object')"
     ]
    }
   ],
   "source": [
    "tubes_tied.join(tubal_ligation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubal_ligation.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = tubal_ligation.append([depo, ring, implant, pill, condom, patch, IUD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentences.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.to_csv(\"Sentences to Rate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a function that \n",
    "#counts the occurence of each side effect in the text and\n",
    "#populates the columns named by the side effect type\n",
    "\n",
    "side_effects = [\"pain\", \"cramp\", \"bleed\", \"spot\", \"irregular\", \"mood swing\", \"depressed\", \"weight gain\", \"weight loss\",\n",
    "                \"headache\", \"ache\", \"acne\", \"nausea\", \"dizzy\", \"discomfort\", \"perforate\", \"tender\", \"discharge\",\n",
    "                \"irritate\", \"infect\", \"allergic\", \"burn\", \"rash\", \"itch\", \"tire\", \"vomit\"]\n",
    "def counting_effects(dataFrame, text_field, side_effects):\n",
    "    effects = np.zeros([dataFrame.shape[0],len(side_effects)])\n",
    "    for i in range(dataFrame.shape[0]):\n",
    "        entry = dataFrame[text_field][i]\n",
    "        for j in range(len(side_effects)):\n",
    "#             print(entry)\n",
    "            this_effect = side_effects[j]\n",
    "            if this_effect in entry:\n",
    "#                 print(this_effect)\n",
    "                effects[i,j] = 1\n",
    "    return effects\n",
    "    \n",
    "IUD_counts = counting_effects(IUD, \"SENTENCE\", side_effects)\n",
    "pill_counts = counting_effects(pill, \"SENTENCE\", side_effects)\n",
    "condom_counts = counting_effects(condom, \"SENTENCE\", side_effects)\n",
    "patch_counts = counting_effects(patch, \"SENTENCE\", side_effects)\n",
    "ring_counts = counting_effects(ring, \"SENTENCE\", side_effects)\n",
    "depo_counts = counting_effects(depo, \"SENTENCE\", side_effects)\n",
    "implant_counts = counting_effects(implant, \"SENTENCE\", side_effects)\n",
    "tubes_counts = counting_effects(tubal_ligation, \"SENTENCE\", side_effects)\n",
    "\n",
    "##Creates a dataframe with the counts \n",
    "IUDcounts = pd.DataFrame(IUD_counts, columns = side_effects)\n",
    "pillcounts = pd.DataFrame(pill_counts, columns = side_effects)\n",
    "condomcounts = pd.DataFrame(condom_counts, columns = side_effects)\n",
    "patchcounts = pd.DataFrame(patch_counts, columns = side_effects)\n",
    "ringcounts = pd.DataFrame(ring_counts, columns = side_effects)\n",
    "depocounts = pd.DataFrame(depo_counts, columns = side_effects)\n",
    "implantcounts = pd.DataFrame(implant_counts, columns = side_effects)\n",
    "tubescounts = pd.DataFrame(tubes_counts, columns = side_effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Joining sentences with counts\n",
    "IUD_total = IUD.join(IUDcounts)\n",
    "pill_total = pill.join(pillcounts)\n",
    "condom_total = condom.join(condomcounts)\n",
    "patch_total = patch.join(patchcounts)\n",
    "ring_total = ring.join(ringcounts)\n",
    "depo_total = depo.join(depocounts)\n",
    "implant_total = implant.join(implantcounts)\n",
    "tubes_total = tubal_ligation.join(tubescounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have each sentence with mention of a side effect.\n",
    "**Next we need to analyze the sentiment of each sentence in the dataframe. A good package to start with would be NLTK sentiment analyzer. Stanford Core NLP analyzes the whole paragraph of text, by splitting individual sentences and analyzing each sentence by itself. Might be useful to conduct a tree parser to see how NLTK treats sentences?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SENTIMENT ANALYSIS ON IUD SENTENCES --\n",
    "\n",
    "sia = SIA()\n",
    "results_body = []\n",
    "for entry in IUD_total[\"SENTENCE\"]:\n",
    "    body_score = sia.polarity_scores(entry)\n",
    "    body_score['SENTENCE'] = entry\n",
    "    results_body.append(body_score)\n",
    "IUD_results = pd.DataFrame(results_body)\n",
    "\n",
    "IUD_sentiments = pd.merge(IUD_total, IUD_results, on='SENTENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENTIMENT ANALYSIS ON pill SENTENCES --\n",
    "\n",
    "sia = SIA()\n",
    "results_body = []\n",
    "for entry in pill_total[\"SENTENCE\"]:\n",
    "    body_score = sia.polarity_scores(entry)\n",
    "    body_score['SENTENCE'] = entry\n",
    "    results_body.append(body_score)\n",
    "pill_results = pd.DataFrame(results_body)\n",
    "\n",
    "pill_sentiments = pd.merge(pill_total, pill_results, on='SENTENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENTIMENT ANALYSIS ON patch SENTENCES --\n",
    "\n",
    "sia = SIA()\n",
    "results_body = []\n",
    "for entry in patch_total[\"SENTENCE\"]:\n",
    "    body_score = sia.polarity_scores(entry)\n",
    "    body_score['SENTENCE'] = entry\n",
    "    results_body.append(body_score)\n",
    "patch_results = pd.DataFrame(results_body)\n",
    "\n",
    "patch_sentiments = pd.merge(patch_total, patch_results, on='SENTENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENTIMENT ANALYSIS ON implant SENTENCES --\n",
    "\n",
    "sia = SIA()\n",
    "results_body = []\n",
    "for entry in implant_total[\"SENTENCE\"]:\n",
    "    body_score = sia.polarity_scores(entry)\n",
    "    body_score['SENTENCE'] = entry\n",
    "    results_body.append(body_score)\n",
    "implant_results = pd.DataFrame(results_body)\n",
    "\n",
    "implant_sentiments = pd.merge(implant_total, implant_results, on='SENTENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENTIMENT ANALYSIS ON ring SENTENCES --\n",
    "\n",
    "sia = SIA()\n",
    "results_body = []\n",
    "for entry in ring_total[\"SENTENCE\"]:\n",
    "    body_score = sia.polarity_scores(entry)\n",
    "    body_score['SENTENCE'] = entry\n",
    "    results_body.append(body_score)\n",
    "ring_results = pd.DataFrame(results_body)\n",
    "\n",
    "ring_sentiments = pd.merge(ring_total, ring_results, on='SENTENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENTIMENT ANALYSIS ON tubal ligation SENTENCES --\n",
    "\n",
    "sia = SIA()\n",
    "results_body = []\n",
    "for entry in tubes_total[\"SENTENCE\"]:\n",
    "    body_score = sia.polarity_scores(entry)\n",
    "    body_score['SENTENCE'] = entry\n",
    "    results_body.append(body_score)\n",
    "tubes_results = pd.DataFrame(results_body)\n",
    "\n",
    "tubes_sentiments = pd.merge(tubes_total, tubes_results, on='SENTENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENTIMENT ANALYSIS ON depo SENTENCES --\n",
    "\n",
    "sia = SIA()\n",
    "results_body = []\n",
    "for entry in depo_total[\"SENTENCE\"]:\n",
    "    body_score = sia.polarity_scores(entry)\n",
    "    body_score['SENTENCE'] = entry\n",
    "    results_body.append(body_score)\n",
    "depo_results = pd.DataFrame(results_body)\n",
    "\n",
    "depo_sentiments = pd.merge(depo_total, depo_results, on='SENTENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENTIMENT ANALYSIS ON condom SENTENCES --\n",
    "\n",
    "sia = SIA()\n",
    "results_body = []\n",
    "for entry in condom_total[\"SENTENCE\"]:\n",
    "    body_score = sia.polarity_scores(entry)\n",
    "    body_score['SENTENCE'] = entry\n",
    "    results_body.append(body_score)\n",
    "condom_results = pd.DataFrame(results_body)\n",
    "\n",
    "condom_sentiments = pd.merge(condom_total, condom_results, on='SENTENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>pain</th>\n",
       "      <th>cramp</th>\n",
       "      <th>bleed</th>\n",
       "      <th>spot</th>\n",
       "      <th>irregular</th>\n",
       "      <th>mood swing</th>\n",
       "      <th>depress</th>\n",
       "      <th>weight gain</th>\n",
       "      <th>...</th>\n",
       "      <th>allerg</th>\n",
       "      <th>burn</th>\n",
       "      <th>rash</th>\n",
       "      <th>itch</th>\n",
       "      <th>tire</th>\n",
       "      <th>vomit</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8s6sb4</td>\n",
       "      <td>its my first time having sex without a condom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8s7d94</td>\n",
       "      <td>i want to stop because of some very bad side e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2484</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8s88p4</td>\n",
       "      <td>so i had a scare and i m unprotected (condom b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.8261</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8s9sz7</td>\n",
       "      <td>condom slipped and didn t notice, felt 2  puls...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8scn8c</td>\n",
       "      <td>he has suggested condoms because he doesnt wan...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6889</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8scn8c</td>\n",
       "      <td>here are the options i have narrowed it down t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8rx01f</td>\n",
       "      <td>hello!i've been on and off the pill for about ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8ry9g7</td>\n",
       "      <td>me and my boyfriend were having sex and the co...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8ry9g7</td>\n",
       "      <td>we switched condoms.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8s1ly4</td>\n",
       "      <td>me and boyfriend use condoms.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                           SENTENCE  pain  cramp  \\\n",
       "0  8s6sb4      its my first time having sex without a condom   0.0    0.0   \n",
       "1  8s7d94  i want to stop because of some very bad side e...   0.0    0.0   \n",
       "2  8s88p4  so i had a scare and i m unprotected (condom b...   0.0    0.0   \n",
       "3  8s9sz7  condom slipped and didn t notice, felt 2  puls...   0.0    0.0   \n",
       "4  8scn8c  he has suggested condoms because he doesnt wan...   0.0    0.0   \n",
       "5  8scn8c  here are the options i have narrowed it down t...   1.0    0.0   \n",
       "6  8rx01f  hello!i've been on and off the pill for about ...   0.0    0.0   \n",
       "7  8ry9g7  me and my boyfriend were having sex and the co...   0.0    0.0   \n",
       "8  8ry9g7                               we switched condoms.   0.0    0.0   \n",
       "9  8s1ly4                      me and boyfriend use condoms.   0.0    0.0   \n",
       "\n",
       "   bleed  spot  irregular  mood swing  depress  weight gain  ...    allerg  \\\n",
       "0    0.0   0.0        0.0         0.0      0.0          0.0  ...       0.0   \n",
       "1    0.0   0.0        0.0         0.0      0.0          0.0  ...       0.0   \n",
       "2    0.0   0.0        0.0         0.0      0.0          0.0  ...       0.0   \n",
       "3    0.0   0.0        0.0         0.0      0.0          0.0  ...       0.0   \n",
       "4    0.0   0.0        0.0         0.0      0.0          0.0  ...       0.0   \n",
       "5    0.0   1.0        0.0         0.0      0.0          0.0  ...       0.0   \n",
       "6    0.0   0.0        0.0         0.0      0.0          0.0  ...       0.0   \n",
       "7    0.0   0.0        0.0         0.0      0.0          0.0  ...       0.0   \n",
       "8    0.0   0.0        0.0         0.0      0.0          0.0  ...       0.0   \n",
       "9    0.0   0.0        0.0         0.0      0.0          0.0  ...       0.0   \n",
       "\n",
       "   burn  rash  itch  tire  vomit  compound    neg    neu    pos  \n",
       "0   0.0   0.0   0.0   0.0    0.0    0.0000  0.000  1.000  0.000  \n",
       "1   0.0   0.0   0.0   0.0    0.0   -0.2484  0.214  0.607  0.179  \n",
       "2   0.0   0.0   0.0   0.0    0.0   -0.8261  0.183  0.773  0.043  \n",
       "3   0.0   0.0   0.0   0.0    0.0    0.0000  0.000  1.000  0.000  \n",
       "4   0.0   0.0   0.0   0.0    0.0   -0.6889  0.153  0.847  0.000  \n",
       "5   0.0   0.0   0.0   0.0    0.0    0.0622  0.150  0.706  0.144  \n",
       "6   0.0   0.0   0.0   0.0    0.0    0.0000  0.000  1.000  0.000  \n",
       "7   0.0   0.0   0.0   0.0    0.0   -0.4215  0.113  0.887  0.000  \n",
       "8   0.0   0.0   1.0   0.0    0.0    0.0000  0.000  1.000  0.000  \n",
       "9   0.0   0.0   0.0   0.0    0.0    0.0000  0.000  1.000  0.000  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condom_sentiments.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pain</th>\n",
       "      <th>cramp</th>\n",
       "      <th>bleed</th>\n",
       "      <th>spot</th>\n",
       "      <th>irregular</th>\n",
       "      <th>mood swing</th>\n",
       "      <th>depressed</th>\n",
       "      <th>weight gain</th>\n",
       "      <th>weight loss</th>\n",
       "      <th>headache</th>\n",
       "      <th>...</th>\n",
       "      <th>allergic</th>\n",
       "      <th>burn</th>\n",
       "      <th>rash</th>\n",
       "      <th>itch</th>\n",
       "      <th>tire</th>\n",
       "      <th>vomit</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1232</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6052</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2942</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6682</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4064</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pain  cramp  bleed  spot  irregular  mood swing  depressed  weight gain  \\\n",
       "0   0.0    0.0    0.0   0.0        0.0         0.0        0.0          0.0   \n",
       "1   0.0    0.0    0.0   0.0        0.0         0.0        0.0          0.0   \n",
       "2   0.0    0.0    0.0   0.0        0.0         0.0        0.0          0.0   \n",
       "3   0.0    0.0    0.0   0.0        0.0         0.0        0.0          0.0   \n",
       "4   0.0    0.0    0.0   0.0        0.0         0.0        0.0          0.0   \n",
       "5   0.0    0.0    0.0   0.0        0.0         0.0        0.0          0.0   \n",
       "6   0.0    0.0    0.0   0.0        0.0         0.0        0.0          0.0   \n",
       "7   0.0    0.0    0.0   0.0        0.0         0.0        0.0          0.0   \n",
       "8   0.0    0.0    0.0   0.0        0.0         0.0        0.0          0.0   \n",
       "9   0.0    0.0    1.0   0.0        0.0         0.0        0.0          0.0   \n",
       "\n",
       "   weight loss  headache  ...    allergic  burn  rash  itch  tire  vomit  \\\n",
       "0          0.0       0.0  ...         0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "1          0.0       0.0  ...         0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "2          0.0       0.0  ...         0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "3          0.0       0.0  ...         0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "4          0.0       0.0  ...         0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "5          0.0       0.0  ...         0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "6          0.0       0.0  ...         0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "7          0.0       0.0  ...         0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "8          0.0       0.0  ...         0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "9          0.0       0.0  ...         0.0   0.0   0.0   1.0   0.0    0.0   \n",
       "\n",
       "   compound    neg    neu    pos  \n",
       "0   -0.1232  0.080  0.920  0.000  \n",
       "1    0.0000  0.000  1.000  0.000  \n",
       "2    0.2732  0.045  0.874  0.081  \n",
       "3   -0.6052  0.165  0.835  0.000  \n",
       "4    0.2942  0.083  0.767  0.150  \n",
       "5    0.0000  0.000  1.000  0.000  \n",
       "6    0.4939  0.000  0.918  0.082  \n",
       "7    0.0000  0.000  1.000  0.000  \n",
       "8    0.6682  0.000  0.711  0.289  \n",
       "9   -0.4064  0.163  0.691  0.146  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tubes_sentiments = tubes_sentiments.drop(['ID', 'SENTENCE'], 1)\n",
    "tubes_sentiments.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the percent of the total occurence of side effects per side effect\n",
    "total = sum(tubes_sentiments.sum())\n",
    "by_effect = tubes_sentiments.sum()\n",
    "percent = (by_effect/total)*100\n",
    "# print(percent)\n",
    "\n",
    "freq = pd.DataFrame(percent)\n",
    "number = pd.DataFrame(by_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "###MULTIPLY ROW VALUE IN COLUMN BY COMPOUD\n",
    "\n",
    "sentiments = pd.DataFrame()\n",
    "for column in tubes_sentiments.columns:\n",
    "    sentiments[column] = tubes_sentiments[column] * tubes_sentiments['compound']\n",
    "\n",
    "sentiments = sentiments.drop(['compound', 'neg', 'neu', 'pos'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_row = {col: sentiments[col].sum() for col in sentiments}\n",
    "sum_df = pd.DataFrame(sum_row, index=[\"Total\"])\n",
    "\n",
    "sums = sum_df.transpose()\n",
    "sums.index.name = 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Merge sums of sentiments and number of occurrences by index name\n",
    "final = sums.join(freq)\n",
    "# final = final.join(freq)\n",
    "final.columns = [\"Tubes_Sentiment\", \"Tubes_Freq\"]\n",
    "final.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_sentiments = pd.DataFrame(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Joining all eight sentiment dataframes together?\n",
    "data_frames = [tubes_sentiments, IUD_sentiments, pill_sentiments, patch_sentiments,\n",
    "              implant_sentiments, ring_sentiments, condom_sentiments, depo_sentiments]\n",
    "\n",
    "sentiments_merged = functools.reduce(lambda  left,right: pd.merge(left,right,on=['name'],\n",
    "                                            how='outer'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Tubes_Sentiment</th>\n",
       "      <th>Tubes_Freq</th>\n",
       "      <th>IUD_Sentiment</th>\n",
       "      <th>IUD_Freq</th>\n",
       "      <th>Pill_Sentiment</th>\n",
       "      <th>Pill_Freq</th>\n",
       "      <th>Patch_Sentiment</th>\n",
       "      <th>Patch_Freq</th>\n",
       "      <th>Implant_Sentiment</th>\n",
       "      <th>Implant_Freq</th>\n",
       "      <th>Ring_Sentiment</th>\n",
       "      <th>Ring_Freq</th>\n",
       "      <th>Condom_Sentiment</th>\n",
       "      <th>Condom_Freq</th>\n",
       "      <th>Depo_Sentiment</th>\n",
       "      <th>Depo_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nausea</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0593</td>\n",
       "      <td>0.091723</td>\n",
       "      <td>-16.1546</td>\n",
       "      <td>0.467594</td>\n",
       "      <td>-1.5495</td>\n",
       "      <td>1.197855</td>\n",
       "      <td>-0.7989</td>\n",
       "      <td>0.239917</td>\n",
       "      <td>-11.2268</td>\n",
       "      <td>0.369304</td>\n",
       "      <td>-1.2203</td>\n",
       "      <td>0.239917</td>\n",
       "      <td>-2.2699</td>\n",
       "      <td>0.309607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pain</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>1.605765</td>\n",
       "      <td>-234.5015</td>\n",
       "      <td>5.714342</td>\n",
       "      <td>-125.5167</td>\n",
       "      <td>1.768258</td>\n",
       "      <td>-8.5070</td>\n",
       "      <td>1.524543</td>\n",
       "      <td>-34.8721</td>\n",
       "      <td>2.570537</td>\n",
       "      <td>-230.5848</td>\n",
       "      <td>4.581133</td>\n",
       "      <td>-13.2445</td>\n",
       "      <td>2.570537</td>\n",
       "      <td>-12.1213</td>\n",
       "      <td>2.244651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>perforate</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.3843</td>\n",
       "      <td>0.146757</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.2964</td>\n",
       "      <td>0.070344</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rash</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.6165</td>\n",
       "      <td>0.036689</td>\n",
       "      <td>-1.5024</td>\n",
       "      <td>0.042997</td>\n",
       "      <td>-2.3797</td>\n",
       "      <td>0.544480</td>\n",
       "      <td>-0.7887</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>-2.0214</td>\n",
       "      <td>0.061551</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>spot</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.4579</td>\n",
       "      <td>1.935355</td>\n",
       "      <td>4.6053</td>\n",
       "      <td>2.246601</td>\n",
       "      <td>-1.1040</td>\n",
       "      <td>2.069022</td>\n",
       "      <td>-9.5239</td>\n",
       "      <td>2.844728</td>\n",
       "      <td>-0.3975</td>\n",
       "      <td>2.294963</td>\n",
       "      <td>-0.6305</td>\n",
       "      <td>2.844728</td>\n",
       "      <td>-0.9818</td>\n",
       "      <td>2.399455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tender</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.1208</td>\n",
       "      <td>0.018345</td>\n",
       "      <td>4.1255</td>\n",
       "      <td>0.161239</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.5487</td>\n",
       "      <td>0.068548</td>\n",
       "      <td>6.0314</td>\n",
       "      <td>0.202238</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.068548</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.077402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tire</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.4622</td>\n",
       "      <td>0.476960</td>\n",
       "      <td>-16.5977</td>\n",
       "      <td>0.795447</td>\n",
       "      <td>-1.1510</td>\n",
       "      <td>0.435584</td>\n",
       "      <td>-5.4085</td>\n",
       "      <td>0.651203</td>\n",
       "      <td>-12.8353</td>\n",
       "      <td>0.764988</td>\n",
       "      <td>-2.8309</td>\n",
       "      <td>0.651203</td>\n",
       "      <td>-3.7933</td>\n",
       "      <td>0.851419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vomit</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0660</td>\n",
       "      <td>0.100895</td>\n",
       "      <td>-14.5638</td>\n",
       "      <td>0.306355</td>\n",
       "      <td>-0.3268</td>\n",
       "      <td>0.435584</td>\n",
       "      <td>-0.5283</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>-1.1057</td>\n",
       "      <td>0.087930</td>\n",
       "      <td>-0.0145</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>-1.4701</td>\n",
       "      <td>0.154804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>weight gain</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.1997</td>\n",
       "      <td>0.440270</td>\n",
       "      <td>19.8281</td>\n",
       "      <td>0.446095</td>\n",
       "      <td>0.5781</td>\n",
       "      <td>0.544480</td>\n",
       "      <td>12.2185</td>\n",
       "      <td>0.993941</td>\n",
       "      <td>9.9327</td>\n",
       "      <td>0.457234</td>\n",
       "      <td>0.6631</td>\n",
       "      <td>0.993941</td>\n",
       "      <td>2.0150</td>\n",
       "      <td>1.470634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>weight loss</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.7229</td>\n",
       "      <td>0.018345</td>\n",
       "      <td>0.6544</td>\n",
       "      <td>0.037623</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.7141</td>\n",
       "      <td>0.102821</td>\n",
       "      <td>1.2035</td>\n",
       "      <td>0.061551</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.102821</td>\n",
       "      <td>-0.0644</td>\n",
       "      <td>0.077402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  Tubes_Sentiment  Tubes_Freq  IUD_Sentiment  IUD_Freq  \\\n",
       "16       nausea           0.0000    0.000000        -1.0593  0.091723   \n",
       "17         pain           0.8555    1.605765      -234.5015  5.714342   \n",
       "18    perforate           0.0000    0.000000        -0.3843  0.146757   \n",
       "19         rash           0.0000    0.000000        -1.6165  0.036689   \n",
       "20         spot           0.0000    0.000000        -1.4579  1.935355   \n",
       "21       tender           0.0000    0.000000         1.1208  0.018345   \n",
       "22         tire           0.0000    0.000000        -8.4622  0.476960   \n",
       "23        vomit           0.0000    0.000000        -1.0660  0.100895   \n",
       "24  weight gain           0.0000    0.000000         9.1997  0.440270   \n",
       "25  weight loss           0.0000    0.000000        -0.7229  0.018345   \n",
       "\n",
       "    Pill_Sentiment  Pill_Freq  Patch_Sentiment  Patch_Freq  Implant_Sentiment  \\\n",
       "16        -16.1546   0.467594          -1.5495    1.197855            -0.7989   \n",
       "17       -125.5167   1.768258          -8.5070    1.524543           -34.8721   \n",
       "18          0.0000   0.000000           0.0000    0.000000             0.0000   \n",
       "19         -1.5024   0.042997          -2.3797    0.544480            -0.7887   \n",
       "20          4.6053   2.246601          -1.1040    2.069022            -9.5239   \n",
       "21          4.1255   0.161239           0.0000    0.000000             1.5487   \n",
       "22        -16.5977   0.795447          -1.1510    0.435584            -5.4085   \n",
       "23        -14.5638   0.306355          -0.3268    0.435584            -0.5283   \n",
       "24         19.8281   0.446095           0.5781    0.544480            12.2185   \n",
       "25          0.6544   0.037623           0.0000    0.000000            -1.7141   \n",
       "\n",
       "    Implant_Freq  Ring_Sentiment  Ring_Freq  Condom_Sentiment  Condom_Freq  \\\n",
       "16      0.239917        -11.2268   0.369304           -1.2203     0.239917   \n",
       "17      2.570537       -230.5848   4.581133          -13.2445     2.570537   \n",
       "18      0.000000         -2.2964   0.070344            0.0000     0.000000   \n",
       "19      0.034274         -2.0214   0.061551            0.2191     0.034274   \n",
       "20      2.844728         -0.3975   2.294963           -0.6305     2.844728   \n",
       "21      0.068548          6.0314   0.202238            0.5719     0.068548   \n",
       "22      0.651203        -12.8353   0.764988           -2.8309     0.651203   \n",
       "23      0.034274         -1.1057   0.087930           -0.0145     0.034274   \n",
       "24      0.993941          9.9327   0.457234            0.6631     0.993941   \n",
       "25      0.102821          1.2035   0.061551            0.8692     0.102821   \n",
       "\n",
       "    Depo_Sentiment  Depo_Freq  \n",
       "16         -2.2699   0.309607  \n",
       "17        -12.1213   2.244651  \n",
       "18          0.0000   0.000000  \n",
       "19          0.0000   0.000000  \n",
       "20         -0.9818   2.399455  \n",
       "21          0.4588   0.077402  \n",
       "22         -3.7933   0.851419  \n",
       "23         -1.4701   0.154804  \n",
       "24          2.0150   1.470634  \n",
       "25         -0.0644   0.077402  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_merged.to_csv('all_side_effects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Labeling posts as \"positive\" or \"negative\"\n",
    "##Decided to get rid of \"neutral\" posts by lumping them in with positives. Should I go ahead and drop them altogether?\n",
    "IUD_sentiments['label'] = 0\n",
    "IUD_sentiments.loc[IUD_sentiments['compound'] >= 0.0, 'label'] = 1\n",
    "IUD_sentiments.loc[IUD_sentiments['compound'] < -0.0, 'label'] = -1\n",
    "\n",
    "##Proportion of posts that are positive/negative:\n",
    "# print(IUD_sentiments.label.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###CREATE SCATTERPLOT WITH QUADRANTS\n",
    "p1=sns.regplot(data=final, x=\"Sentiment\", y=\"Freq\", fit_reg=False, marker=\"o\", color=\"skyblue\", scatter_kws={'s':400})\n",
    "\n",
    "for line in range(0,final.shape[0]):\n",
    "     p1.text(final.Sentiment[line]+0.2, final.Freq[line], final.name[line], horizontalalignment='left', size='medium', color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###USE GROUPBY FOR SENTI BY SIDE EFFECT = 1\n",
    "###Maybe drop rows that have no side effects? Try with all rows first\n",
    "# IUD_sentiments[IUD_sentiments[column]==1].groupby(column, as_index=False)['compound'].mean()\n",
    "\n",
    "senti = {}\n",
    "for column in IUD_sentiments.columns:\n",
    "    output = IUD_sentiments[IUD_sentiments[column]==1].groupby(column, as_index = False)['compound'].mean()\n",
    "    if not output.empty:\n",
    "#         print(output)\n",
    "        senti[column] = output['compound'][1]\n",
    "#     print(output['compound'])\n",
    "#     total_senti.append(senti)\n",
    "#     senti[column] = IUD_sentiments[IUD_sentiments[column]==1].groupby(column, as_index=False)['compound'].mean()\n",
    "#     IUD_sentiments.groupby('pain', as_index=False)['compound'].mean()\n",
    "print(senti)\n",
    "\n",
    "# print(output)\n",
    "# pd.DataFrame(senti.items()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tokenize words\n",
    "\n",
    "body_tokenized = []\n",
    "\n",
    "for entry in new[\"selftext\"]:\n",
    "    tokens = nltk.word_tokenize(entry)\n",
    "    body_tokenized.append(tokens)\n",
    "    \n",
    "new[\"body_tokenized\"] = body_tokenized\n",
    "new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dropping stop words from tokenized list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "keepwords = ['against', 'ain', \"aren't\", 'but', \"couldn't\", 'couldn', \"didn't\", 'doesn'\n",
    "                 , \"doesn't\", 'don', \"don't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\"\n",
    "                 , 'haven', \"haven't\", 'isn', \"isn't\", 'll', 'mightn', \"mightn't\"\n",
    "                 , 'mustn', \"mustn't\", 'needn', \"needn't\", 'no', \"not\", \"nor\", \"only\"\n",
    "                 , \"shan\", \"shan't\", \"shouldn't\", \"should've\", \"shouldn\", \"wasn\", \"wasn't\"\n",
    "                 , \"weren\", \"weren't\", \"won't\", \"wouldn\", \"wouldn't\"]\n",
    "\n",
    "for keepword in keepwords:\n",
    "    if keepword in stop_words:\n",
    "        stop_words.remove(keepword)\n",
    "\n",
    "\n",
    "body_new = []\n",
    "\n",
    "for entry in new[\"body_tokenized\"]:\n",
    "    filtered_sentence = [w for w in entry if not w in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in entry:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    body_new.append(filtered_sentence)\n",
    "    \n",
    "new[\"body_new\"] = body_new\n",
    "new.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##tokenize and lemmatize each text body entry in dataframe\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "body_lemmatized = []\n",
    "\n",
    "for entry in new[\"body_new\"]:\n",
    "    templist = []\n",
    "    for word in entry:\n",
    "        lemma = lemmatizer.lemmatize(word)\n",
    "        templist.append(lemma)\n",
    "    body_lemmatized.append(templist)\n",
    "\n",
    "new[\"body_lemmatized\"] = body_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_lemma = []\n",
    "for entry in new[\"body_lemmatized\"]:\n",
    "    body_lemma.append(\" \".join(entry))\n",
    "\n",
    "new[\"body_clean\"] = body_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[\"body_clean\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split sentences in selftext & title and put in a dataframe?\n",
    "\n",
    "body_sentences = []\n",
    "comment_id = []\n",
    "for counter in np.arange(IUD.shape[0]):\n",
    "    sentences = sent_tokenize(IUD[\"selftext\"][i])\n",
    "    body_sentences.append(sentences)\n",
    "    comment_id.append()\n",
    "\n",
    "# print(body_sentences)\n",
    "\n",
    "#Flattening list of lists into a single list\n",
    "flatten = lambda l: [item for sublist in body_sentences for item in sublist]\n",
    "flatten(body_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
